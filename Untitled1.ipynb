{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM14s/843ZRIzf1ysPqJm6G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadycoul12/Projet-personnel/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 selenium\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFt_D1obGHcx",
        "outputId": "e71625ec-cdd7-4e39-e7f3-63f0aac327ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.28.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.28.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options"
      ],
      "metadata": {
        "id": "X8JNLRdUZdg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "''''\n",
        "# Configuration Selenium\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "service = Service('C:\\\\chromedriver\\\\chromedriver.exe')\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# URL du site IQAir\n",
        "url = \"https://www.iqair.com/\"\n",
        "\n",
        "# Accéder à la page via Selenium\n",
        "driver.get(url)\n",
        "html_content = driver.page_source\n",
        "driver.quit()\n",
        "\n",
        "# Analyser le HTML avec BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Collecte des données pour les villes\n",
        "cities_data = []\n",
        "cities = soup.find_all('div', class_='some-city-class')  # Ajustez selon la classe réelle\n",
        "\n",
        "for city in cities:\n",
        "    try:\n",
        "        city_name = city.find('h3', class_='city-name-class').text.strip()  # Nom de la ville\n",
        "        aqi = city.find('span', class_='aqi-value-class').text.strip()  # Indice AQI\n",
        "        pollutants = city.find_all('div', class_='pollutant-class')  # Liste des polluants\n",
        "\n",
        "        pm25 = pollutants[0].text.strip() if pollutants else \"N/A\"\n",
        "        pm10 = pollutants[1].text.strip() if pollutants else \"N/A\"\n",
        "        co = pollutants[2].text.strip() if pollutants else \"N/A\"\n",
        "        no2 = pollutants[3].text.strip() if pollutants else \"N/A\"\n",
        "        so2 = pollutants[4].text.strip() if pollutants else \"N/A\"\n",
        "        ozone = pollutants[5].text.strip() if pollutants else \"N/A\"\n",
        "\n",
        "        timestamp = city.find('span', class_='timestamp-class').text.strip()  # Dernière mise à jour\n",
        "\n",
        "        cities_data.append({\n",
        "            'City': city_name,\n",
        "            'AQI': aqi,\n",
        "            'PM2.5': pm25,\n",
        "            'PM10': pm10,\n",
        "            'CO': co,\n",
        "            'NO2': no2,\n",
        "            'SO2': so2,\n",
        "            'Ozone': ozone,\n",
        "            'Last Updated': timestamp\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du traitement d'une ville : {e}\")\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "M6kXtNa6ZddY",
        "outputId": "ab94cc9b-67e8-4ac1-f89c-2e6484f9260a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\'\\n# Configuration Selenium\\nchrome_options = Options()\\nchrome_options.add_argument(\"--headless\")\\nservice = Service(\\'C:\\\\chromedriver\\\\chromedriver.exe\\')  \\ndriver = webdriver.Chrome(service=service, options=chrome_options)\\n\\n# URL du site IQAir\\nurl = \"https://www.iqair.com/\"\\n\\n# Accéder à la page via Selenium\\ndriver.get(url)\\nhtml_content = driver.page_source\\ndriver.quit()\\n\\n# Analyser le HTML avec BeautifulSoup\\nsoup = BeautifulSoup(html_content, \\'html.parser\\')\\n\\n# Collecte des données pour les villes\\ncities_data = []\\ncities = soup.find_all(\\'div\\', class_=\\'some-city-class\\')  # Ajustez selon la classe réelle\\n\\nfor city in cities:\\n    try:\\n        city_name = city.find(\\'h3\\', class_=\\'city-name-class\\').text.strip()  # Nom de la ville\\n        aqi = city.find(\\'span\\', class_=\\'aqi-value-class\\').text.strip()  # Indice AQI\\n        pollutants = city.find_all(\\'div\\', class_=\\'pollutant-class\\')  # Liste des polluants\\n\\n        pm25 = pollutants[0].text.strip() if pollutants else \"N/A\"\\n        pm10 = pollutants[1].text.strip() if pollutants else \"N/A\"\\n        co = pollutants[2].text.strip() if pollutants else \"N/A\"\\n        no2 = pollutants[3].text.strip() if pollutants else \"N/A\"\\n        so2 = pollutants[4].text.strip() if pollutants else \"N/A\"\\n        ozone = pollutants[5].text.strip() if pollutants else \"N/A\"\\n\\n        timestamp = city.find(\\'span\\', class_=\\'timestamp-class\\').text.strip()  # Dernière mise à jour\\n\\n        cities_data.append({\\n            \\'City\\': city_name,\\n            \\'AQI\\': aqi,\\n            \\'PM2.5\\': pm25,\\n            \\'PM10\\': pm10,\\n            \\'CO\\': co,\\n            \\'NO2\\': no2,\\n            \\'SO2\\': so2,\\n            \\'Ozone\\': ozone,\\n            \\'Last Updated\\': timestamp\\n        })\\n    except Exception as e:\\n        print(f\"Erreur lors du traitement d\\'une ville : {e}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion en DataFrame\n",
        "df = pd.DataFrame(cities_data)\n",
        "\n",
        "# Sauvegarde au format CSV\n",
        "csv_filename = 'air_quality_data.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "print(f\"Les données ont été enregistrées dans le fichier {csv_filename}.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LAUZZiifdaxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Mining"
      ],
      "metadata": {
        "id": "2SqWJoIriGh5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omHrxTu4iAiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Histogramme\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data['AQI'], kde=True, bins=30, color='blue')\n",
        "plt.title('Distribution des Indices AQI', fontsize=14)\n",
        "plt.xlabel('AQI', fontsize=12)\n",
        "plt.ylabel('Fréquence', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Boxplot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x=data['AQI'], color='green')\n",
        "plt.title('Boxplot de l\\'AQI', fontsize=14)\n",
        "plt.xlabel('AQI', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CcTWSE2LiAUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppdj8sq3iBoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistiques descriptives pour l'AQI et les polluants\n",
        "stats = data[['AQI', 'PM2.5', 'PM10', 'CO', 'NO2', 'SO2', 'Ozone']].describe()\n",
        "print(stats)\n"
      ],
      "metadata": {
        "id": "hKhW2dD8iI9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5y2osuWiO7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Visualisation avancée des données"
      ],
      "metadata": {
        "id": "4-yWtMK6iRjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carte de chaleur des corrélations entre les polluants\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation = data[['AQI', 'PM2.5', 'PM10', 'CO', 'NO2', 'SO2', 'Ozone']].corr()\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Carte de chaleur des corrélations entre les polluants', fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u1DlzpH_iO4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphiques multi-variables\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=data, x='City', y='PM2.5', palette='Set2')\n",
        "plt.title('Comparaison des niveaux de PM2.5 entre les villes', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Villes', fontsize=12)\n",
        "plt.ylabel('PM2.5', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A5eehNMUie2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphes temporels pour suivre l'évolution\n",
        "# Convertir la colonne 'Last Updated' en format datetime\n",
        "data['Last Updated'] = pd.to_datetime(data['Last Updated'])\n",
        "\n",
        "# Exemple : Evolution de l'AQI dans une ville donnée\n",
        "city_data = data[data['City'] == 'Paris']  # Filtrer par ville\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(city_data['Last Updated'], city_data['AQI'], marker='o', label='AQI', color='blue')\n",
        "plt.title('Évolution de l\\'AQI à Paris', fontsize=14)\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('AQI', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9okwR-1Rimeg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}